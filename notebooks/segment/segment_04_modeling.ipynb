{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "style"
    ]
   },
   "outputs": [],
   "source": [
    "from airline_revenue_analytics.viz.charts import apply_style, PLOT_COLORS\n",
    "apply_style()\n",
    "PASS_COLOR = \"#D9F2E6\"\n",
    "FAIL_COLOR = \"#FCE4E4\"\n",
    "NEG_BG_COLOR = FAIL_COLOR\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Notebook setup (segment pipeline) / Notebook \u521d\u59cb\u5316\uff08segment \u7ba1\u7ebf\uff09\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from airline_revenue_analytics.config import get_paths\n",
    "except ModuleNotFoundError as exc:\n",
    "    raise ModuleNotFoundError(\"Install the package first: pip install -e .\") from exc\n",
    "\n",
    "# Resolve repo paths and DB location / \u89e3\u6790\u4ed3\u5e93\u8def\u5f84\u4e0e\u6570\u636e\u5e93\u4f4d\u7f6e\n",
    "paths = get_paths(\"segment\")\n",
    "REPO_ROOT = paths.repo_root\n",
    "DATA_DIR = paths.data_raw\n",
    "OUT_DIR = paths.outputs_root\n",
    "FIG_DIR = paths.figures\n",
    "TAB_DIR = paths.tables\n",
    "DB_PATH = paths.db_path\n",
    "db_path = DB_PATH\n",
    "\n",
    "# SQLite connection (shared across cells) / SQLite \u8fde\u63a5\uff08\u5168\u5c40\u590d\u7528\uff09\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "def _rel(p: Path) -> str:\n",
    "    \"\"\"Render repo-relative paths for display / \u5c06\u8def\u5f84\u663e\u793a\u4e3a\u4ed3\u5e93\u76f8\u5bf9\u8def\u5f84.\"\"\"\n",
    "    try:\n",
    "        return str(Path(p).resolve().relative_to(REPO_ROOT))\n",
    "    except Exception:\n",
    "        return str(p)\n",
    "\n",
    "def find_path(filename: str) -> Path:\n",
    "    \"\"\"Locate a file under outputs/ or data/raw / \u5728 outputs/ \u6216 data/raw \u4e2d\u5b9a\u4f4d\u6587\u4ef6.\"\"\"\n",
    "    for p in (OUT_DIR / filename, DATA_DIR / filename, REPO_ROOT / filename):\n",
    "        if p.exists():\n",
    "            return p\n",
    "    for root, _, files in os.walk(OUT_DIR):\n",
    "        if filename in files:\n",
    "            return Path(root) / filename\n",
    "    raise FileNotFoundError(\n",
    "        f\"Cannot find {filename}. Put it under data/raw or outputs/segment.\"\n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "4d2b35551cd342bb8ee2f7c5d6d0b6fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded5d71-9f1c-4f8d-81db-1d2fbc2b1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "if \"X\" not in globals() or \"y\" not in globals():\n",
    "    X = pd.read_parquet(find_path(\"X_features.parquet\"))\n",
    "    y = pd.read_parquet(find_path(\"y_target.parquet\")).squeeze()\n",
    "    y = pd.to_numeric(y, errors=\"coerce\")\n",
    "\n",
    "    dt_cols = [c for c in X.columns if is_datetime64_any_dtype(X[c])]\n",
    "    if dt_cols:\n",
    "        X = X.drop(columns=dt_cols)\n",
    "\n",
    "    for c in X.select_dtypes(include=[\"boolean\", \"bool\"]).columns:\n",
    "        X[c] = X[c].astype(\"int16\")\n",
    "\n",
    "    nullable_ints = [c for c in X.columns if str(X[c].dtype).startswith((\"Int\", \"UInt\"))]\n",
    "    for c in nullable_ints:\n",
    "        X[c] = X[c].astype(\"float64\")\n",
    "\n",
    "    num_cols = list(X.select_dtypes(include=[\"number\"]).columns)\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    print(f\"[Loaded] rows={len(X):,}, num_cols={len(num_cols)}, cat_cols={len(cat_cols)}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Sampling for speed (adjustable) / \u4e3a\u4e86\u901f\u5ea6\u505a\u62bd\u6837\uff08\u53ef\u8c03\uff09\n",
    "def subsample(df, n): \n",
    "    return df.sample(n=min(n, len(df)), random_state=42)\n",
    "\n",
    "X_mi = subsample(X, 100_000)\n",
    "y_mi = y.loc[X_mi.index]\n",
    "\n",
    "pre_mi = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"enc\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "    ]), cat_cols)\n",
    "], remainder=\"drop\", sparse_threshold=0)\n",
    "\n",
    "Xm = pre_mi.fit_transform(X_mi)\n",
    "mi_scores = mutual_info_regression(Xm, y_mi, random_state=42)\n",
    "mi_names  = num_cols + cat_cols\n",
    "\n",
    "mi_df = (pd.DataFrame({\"feature\": mi_names, \"MI\": mi_scores})\n",
    "         .sort_values(\"MI\", ascending=False).reset_index(drop=True))\n",
    "mi_df.to_csv(TAB_DIR/\"table_4_1_0_mutual_information_all.csv\", index=False)\n",
    "\n",
    "# Top-20 \u6761\u5f62\u56fe\n",
    "topk = 20\n",
    "mi_top = mi_df.head(topk)\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(mi_top[\"feature\"][::-1], mi_top[\"MI\"][::-1])\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.title(\"Figure 4.1.1 \u2013 Top Features by Mutual Information\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR/\"figure_4_1_1_mi.png\", dpi=220); plt.show()\n",
    "\n",
    "print(\"Saved: figures/figure_4_1_1_mi.png, tables/table_4_1_0_mutual_information_all.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d44dc0-e16b-44cf-ba0e-6183e01ffb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "# \u5f3a\u5236\u4f7f\u7528 Jupyter \u5185\u5d4c\u540e\u7aef\u5e76\u63d0\u9ad8\u6e05\u6670\u5ea6\n",
    "try:\n",
    "    import matplotlib_inline.backend_inline as _mi\n",
    "    _mi.set_matplotlib_formats('retina')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load features and target / \u8bfb\u53d6\u7279\u5f81\u4e0e\u76ee\u6807\n",
    "X = pd.read_parquet(find_path(\"X_features.parquet\"))\n",
    "y = pd.read_parquet(find_path(\"y_target.parquet\")).squeeze()\n",
    "y = pd.to_numeric(y, errors=\"coerce\")\n",
    "\n",
    "# \u2014\u2014 \u6e05\u7406 dtype\uff1a\u53bb\u6389 datetime\uff0c\u5e03\u5c14\u8f6c int\uff0cpandas nullable \u6574\u6570\u8f6c float\n",
    "dt_cols = [c for c in X.columns if is_datetime64_any_dtype(X[c])]\n",
    "if dt_cols:\n",
    "    X = X.drop(columns=dt_cols)\n",
    "\n",
    "for c in X.select_dtypes(include=[\"boolean\", \"bool\"]).columns:\n",
    "    X[c] = X[c].astype(\"int16\")\n",
    "\n",
    "nullable_ints = [c for c in X.columns if str(X[c].dtype).startswith((\"Int\", \"UInt\"))]\n",
    "for c in nullable_ints:\n",
    "    X[c] = X[c].astype(\"float64\")\n",
    "\n",
    "num_cols = list(X.select_dtypes(include=[\"number\"]).columns)\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "print(f\"[Loaded] rows={len(X):,}, num_cols={len(num_cols)}, cat_cols={len(cat_cols)}\")\n",
    "\n",
    "# Train/test split + sampling helpers (for speed) / \u8bad\u7ec3/\u6d4b\u8bd5\u5212\u5206 + \u91c7\u6837\u51fd\u6570\uff08\u52a0\u901f\u7528\uff09\n",
    "rng = np.random.RandomState(42)\n",
    "def subsample(df, n, seed=42):\n",
    "    return df.sample(n=min(n, len(df)), random_state=seed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# \u7248\u672c\u517c\u5bb9\u7684\u4e00\u6b21\u6027 OneHotEncoder\n",
    "try:\n",
    "    _ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    _ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "pre_rf = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", _ohe)\n",
    "    ]), cat_cols)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "pipe_rf = Pipeline([(\"pre\", pre_rf), (\"rf\", rf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5361a8-a5cd-4434-963f-ee22658dbb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf = subsample(X_train, 200_000)\n",
    "y_train_rf = y_train.loc[X_train_rf.index]\n",
    "pipe_rf.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "ohe_pipe = pipe_rf.named_steps[\"pre\"].named_transformers_.get(\"cat\")\n",
    "enc_names = []\n",
    "if ohe_pipe is not None:\n",
    "    enc = ohe_pipe.named_steps[\"ohe\"]\n",
    "    if hasattr(enc, \"get_feature_names_out\"):\n",
    "        enc_names = list(enc.get_feature_names_out(cat_cols))\n",
    "    else:\n",
    "        enc_names = list(enc.get_feature_names(cat_cols))\n",
    "\n",
    "feat_names_enc = list(num_cols) + enc_names\n",
    "imp_enc = pipe_rf.named_steps[\"rf\"].feature_importances_\n",
    "\n",
    "def to_original(name):\n",
    "    for c in cat_cols:\n",
    "        if name.startswith(c + \"_\"):\n",
    "            return c\n",
    "    return name\n",
    "\n",
    "imp_df = (pd.DataFrame({\"encoded_feature\": feat_names_enc, \"importance\": imp_enc})\n",
    "          .assign(feature=lambda d: d[\"encoded_feature\"].map(to_original))\n",
    "          .groupby(\"feature\", as_index=False)[\"importance\"].sum()\n",
    "          .sort_values(\"importance\", ascending=False)\n",
    "          .reset_index(drop=True))\n",
    "\n",
    "imp_df.to_csv(TAB_DIR/\"table_4_1_0_rf_impurity_all.csv\", index=False)\n",
    "\n",
    "top25_imp = imp_df.head(25)\n",
    "fig1, ax1 = plt.subplots(figsize=(9, 6))\n",
    "ax1.barh(top25_imp[\"feature\"][::-1], top25_imp[\"importance\"][::-1])\n",
    "ax1.set_xlabel(\"RF impurity-based importance\")\n",
    "ax1.set_title(\"Figure 4.1.2A \u2013 Random Forest: Impurity-based Importance\")\n",
    "fig1.tight_layout(); fig1.savefig(FIG_DIR/\"figure_4_1_2_impurity.png\", dpi=220)\n",
    "plt.show()\n",
    "display(Image(filename=str(FIG_DIR/\"figure_4_1_2_impurity.png\")))\n",
    "\n",
    "X_test_perm = subsample(X_test, 50_000)\n",
    "y_test_perm = y.loc[X_test_perm.index]\n",
    "perm = permutation_importance(\n",
    "    pipe_rf, X_test_perm, y_test_perm,\n",
    "    n_repeats=5, random_state=42, n_jobs=-1, scoring=\"r2\"\n",
    ")\n",
    "perm_df = (pd.DataFrame({\"feature\": X_test_perm.columns, \"perm_importance\": perm.importances_mean})\n",
    "           .sort_values(\"perm_importance\", ascending=False)\n",
    "           .reset_index(drop=True))\n",
    "perm_df.to_csv(TAB_DIR/\"table_4_1_0_rf_permutation_all.csv\", index=False)\n",
    "\n",
    "top25_perm = perm_df.head(25)\n",
    "fig2, ax2 = plt.subplots(figsize=(9, 6))\n",
    "ax2.barh(top25_perm[\"feature\"][::-1], top25_perm[\"perm_importance\"][::-1])\n",
    "ax2.set_xlabel(\"Permutation importance (\u0394R\u00b2)\")\n",
    "ax2.set_title(\"Figure 4.1.2B \u2013 Random Forest: Permutation Importance\")\n",
    "fig2.tight_layout(); fig2.savefig(FIG_DIR/\"figure_4_1_2_permutation.png\", dpi=220)\n",
    "plt.show()\n",
    "display(Image(filename=str(FIG_DIR/\"figure_4_1_2_permutation.png\")))\n",
    "\n",
    "fig_combo, (axL, axR) = plt.subplots(1, 2, figsize=(14, 6), sharey=False)\n",
    "axL.barh(top25_imp[\"feature\"][::-1], top25_imp[\"importance\"][::-1]); axL.set_title(\"Impurity-based\"); axL.set_xlabel(\"Importance\")\n",
    "axR.barh(top25_perm[\"feature\"][::-1], top25_perm[\"perm_importance\"][::-1]); axR.set_title(\"Permutation (\u0394R\u00b2)\"); axR.set_xlabel(\"Importance\")\n",
    "fig_combo.suptitle(\"Figure 4.1.2 \u2013 Feature Importance from Random Forest\", y=1.02)\n",
    "fig_combo.tight_layout()\n",
    "fig_combo.savefig(FIG_DIR/\"figure_4_1_2_random_forest_both.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "display(Image(filename=str(FIG_DIR/\"figure_4_1_2_random_forest_both.png\")))\n",
    "\n",
    "final_shortlist = sorted(set(top25_imp[\"feature\"]) | set(top25_perm[\"feature\"]))\n",
    "pd.Series(final_shortlist, name=\"final_features\").to_csv(TAB_DIR/\"final_feature_shortlist.txt\", index=False)\n",
    "print(f\"Final shortlisted features ({len(final_shortlist)}):\", final_shortlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388812e1-9060-4a80-aec6-5dd8e5309cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# \u4ec5\u5bf9\u6570\u503c\u5217\u8ba1\u7b97 VIF\uff08\u5148\u4e2d\u4f4d\u6570\u586b\u8865\u518d\u6807\u51c6\u5316\uff09\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "X_num = pd.DataFrame(num_imputer.fit_transform(X[num_cols]), columns=num_cols)\n",
    "scaler = StandardScaler()\n",
    "X_num_sc = pd.DataFrame(scaler.fit_transform(X_num), columns=num_cols)\n",
    "\n",
    "vif_rows = [{\"Feature\": col, \"VIF\": float(variance_inflation_factor(X_num_sc.values, i))}\n",
    "            for i, col in enumerate(X_num_sc.columns)]\n",
    "vif_df = pd.DataFrame(vif_rows).sort_values(\"VIF\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# \u5728 Jupyter \u663e\u793a + \u5bfc\u51fa CSV\n",
    "try:\n",
    "    display(vif_df.style.hide(axis=\"index\"))\n",
    "except Exception:\n",
    "    display(vif_df)\n",
    "\n",
    "vif_df.to_csv(TAB_DIR/\"table_4_1_1_vif.csv\", index=False)\n",
    "\n",
    "# \u4fdd\u5b58 PNG \u8868\u683c\uff08\u4fbf\u4e8e\u7c98\u8d34 Word\uff09\n",
    "fig_h = 0.8 + 0.35*len(vif_df)\n",
    "fig, ax = plt.subplots(figsize=(7.5, fig_h))\n",
    "ax.axis(\"off\")\n",
    "tbl = ax.table(cellText=vif_df.round(2).values, colLabels=vif_df.columns,\n",
    "               loc=\"center\", cellLoc=\"center\")\n",
    "tbl.auto_set_font_size(False); tbl.set_fontsize(9); tbl.scale(1, 1.2)\n",
    "plt.title(\"Table 4.1.1 \u2013 VIF for Numeric Predictors\", pad=10)\n",
    "fig.savefig(FIG_DIR/\"figure_4_1_1_vif.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "display(Image(filename=str(FIG_DIR/\"figure_4_1_1_vif.png\")))\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"  figures/figure_4_1_2_impurity.png\")\n",
    "print(\"  figures/figure_4_1_2_permutation.png\")\n",
    "print(\"  figures/figure_4_1_2_random_forest_both.png\")\n",
    "print(\"  figures/figure_4_1_1_vif.png\")\n",
    "print(\"  tables/table_4_1_0_rf_impurity_all.csv\")\n",
    "print(\"  tables/table_4_1_0_rf_permutation_all.csv\")\n",
    "print(\"  tables/table_4_1_1_vif.csv\")\n",
    "print(\"  tables/final_feature_shortlist.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
