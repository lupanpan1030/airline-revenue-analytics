{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "style"
    ]
   },
   "outputs": [],
   "source": [
    "from airline_revenue_analytics.viz.charts import apply_style, PLOT_COLORS\n",
    "apply_style()\n",
    "PASS_COLOR = \"#D9F2E6\"\n",
    "FAIL_COLOR = \"#FCE4E4\"\n",
    "NEG_BG_COLOR = FAIL_COLOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbd1ab5e8848c18dff6e6447fd1a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:35:05.565602Z",
     "iopub.status.busy": "2026-01-11T09:35:05.565456Z",
     "iopub.status.idle": "2026-01-11T09:35:05.575413Z",
     "shell.execute_reply": "2026-01-11T09:35:05.575084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Project paths (booking pipeline)\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"pyproject.toml\").exists() and (p / \"src\" / \"airline_revenue_analytics\").exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "PROJECT_ROOT = REPO_ROOT\n",
    "SRC_ROOT = REPO_ROOT / \"src\"\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SRC_ROOT))\n",
    "\n",
    "from airline_revenue_analytics.config import get_paths\n",
    "\n",
    "PATHS = get_paths(\"booking\")\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "RAW_DIR = PATHS.data_raw\n",
    "DB_PATH = PATHS.db_path\n",
    "OUTPUT_DIR = PATHS.outputs_root\n",
    "FIG_DIR = PATHS.figures\n",
    "TAB_DIR = PATHS.tables\n",
    "ART_DIR = PATHS.artifacts\n",
    "\n",
    "def _rel(p: Path) -> str:\n",
    "    try:\n",
    "        return str(Path(p).resolve().relative_to(REPO_ROOT))\n",
    "    except Exception:\n",
    "        return Path(p).name\n",
    "\n",
    "print(\"REPO_ROOT:\", REPO_ROOT.name)\n",
    "print(\"DB_PATH:\", _rel(DB_PATH))\n",
    "print(\"OUTPUT_DIR:\", _rel(OUTPUT_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Modeling Loop B (Steps 5–7, stronger models + iteration)\n",
    "Goal: train stronger models (regularised linear + boosted tree) on the SAME split,\n",
    "export metrics/predictions/plots, and compare with Loop A for Step 8.5 evidence.\n",
    "\n",
    "Outputs:\n",
    "- `outputs/booking/tables/model_loopB_results.csv`\n",
    "- `outputs/booking/tables/model_comparison_all.csv`                # Loop A + Loop B\n",
    "- `outputs/booking/tables/table_7_1_predictions_loopB.csv`\n",
    "- `outputs/booking/tables/table_5_2_ridge_coefficients_loopB.csv`\n",
    "- `outputs/booking/figures/figure_7_1_residuals_vs_fitted_loopB.png`\n",
    "- `outputs/booking/figures/figure_7_1_actual_vs_pred_loopB.png`\n",
    "- `outputs/booking/artifacts/pipe_ridge_loopB.joblib`\n",
    "- `outputs/booking/artifacts/pipe_hgbr_loopB.joblib`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156808d5-3065-4e38-a947-fe0be5f688b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:35:05.579616Z",
     "iopub.status.busy": "2026-01-11T09:35:05.579521Z",
     "iopub.status.idle": "2026-01-11T09:35:07.942888Z",
     "shell.execute_reply": "2026-01-11T09:35:07.942538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports & paths\n",
    "import sys, pathlib, numpy as np, pandas as pd\n",
    "import matplotlib; import matplotlib.pyplot as plt\n",
    "\n",
    "# ensure \"src\" importable when running from notebooks/\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "# HistGradientBoostingRegressor: enable on very old sklearn\n",
    "try:\n",
    "    from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "    HGBR_AVAILABLE = True\n",
    "except Exception:\n",
    "    from sklearn.ensemble import GradientBoostingRegressor  # fallback\n",
    "    HGBR_AVAILABLE = False\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "OUT_DIR = OUTPUT_DIR\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "TAB_DIR = OUT_DIR / \"tables\"\n",
    "ART_DIR = OUT_DIR / \"artifacts\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"FIG_DIR:\", _rel(FIG_DIR))\n",
    "print(\"TAB_DIR:\", _rel(TAB_DIR))\n",
    "print(\"ART_DIR:\", _rel(ART_DIR), \"| HGBR_AVAILABLE:\", HGBR_AVAILABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7de2c4-6238-49ff-81fc-5f2154fd8a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:35:07.944307Z",
     "iopub.status.busy": "2026-01-11T09:35:07.944142Z",
     "iopub.status.idle": "2026-01-11T09:35:08.247581Z",
     "shell.execute_reply": "2026-01-11T09:35:08.247265Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset built in 02 and split file produced in 03\n",
    "df = pd.read_parquet(TAB_DIR / \"booking_model_df.parquet\")\n",
    "split_ids = pd.read_csv(TAB_DIR / \"table_4_3_1_split_ids.csv\")\n",
    "\n",
    "# Target & features (same as 03/04)\n",
    "target = \"log_total_amount\"\n",
    "num_cols = [\n",
    "    \"n_segments\", \"sum_sched_duration_min\", \"avg_sched_duration_min\",\n",
    "    \"max_sched_duration_min\", \"share_premium_cabin\", \"max_cabin_index\",\n",
    "    \"has_longhaul\", \"n_unique_routes\", \"avg_booking_lead_days\"\n",
    "]\n",
    "\n",
    "# ---------- Reconstruct split (use index if present; otherwise map by book_ref) ----------\n",
    "if \"index\" in split_ids.columns:\n",
    "    idx_train = split_ids.loc[split_ids[\"split\"].eq(\"train\"), \"index\"].to_numpy()\n",
    "    idx_test  = split_ids.loc[~split_ids[\"split\"].eq(\"train\"), \"index\"].to_numpy()\n",
    "else:\n",
    "    idx_map = df.reset_index()[[\"index\", \"book_ref\"]]\n",
    "    merged  = split_ids.merge(idx_map, on=\"book_ref\", how=\"left\", validate=\"one_to_one\")\n",
    "    idx_train = merged.loc[merged[\"split\"].eq(\"train\"), \"index\"].to_numpy()\n",
    "    idx_test  = merged.loc[~merged[\"split\"].eq(\"train\"), \"index\"].to_numpy()\n",
    "\n",
    "# Categorical: top-K route mapping (train-only)\n",
    "cat_raw = df[\"primary_route_code\"].astype(\"string\").fillna(\"Unknown\")\n",
    "top_k = 20\n",
    "top_routes = cat_raw.loc[idx_train].value_counts().index[:top_k].tolist()\n",
    "df[\"primary_route_code_top\"] = np.where(cat_raw.isin(top_routes), cat_raw, \"Other\")\n",
    "cat_cols = [\"primary_route_code_top\"]\n",
    "\n",
    "# Compose X/y\n",
    "X_all = df[num_cols + cat_cols].copy()\n",
    "y_all = df[target].copy()\n",
    "\n",
    "X_train, y_train = X_all.loc[idx_train], y_all.loc[idx_train]\n",
    "X_test,  y_test  = X_all.loc[idx_test],  y_all.loc[idx_test]\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# Convenience aliases (target already log scale)\n",
    "y_train_log, y_test_log = y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98ca91-0230-4985-b4f0-6967bd8fa8d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:35:08.249524Z",
     "iopub.status.busy": "2026-01-11T09:35:08.249408Z",
     "iopub.status.idle": "2026-01-11T09:35:08.260700Z",
     "shell.execute_reply": "2026-01-11T09:35:08.260425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build preprocessor (fit later inside each pipeline)\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), num_cols),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", ohe)\n",
    "    ]), cat_cols),\n",
    "])\n",
    "\n",
    "pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d231222-688e-43d8-b07d-4c175777cb87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:35:08.262040Z",
     "iopub.status.busy": "2026-01-11T09:35:08.261951Z",
     "iopub.status.idle": "2026-01-11T09:35:08.264395Z",
     "shell.execute_reply": "2026-01-11T09:35:08.264019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Version-robust evaluation (handles old sklearn without squared=)\n",
    "def evaluate(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    r2 = float(r2_score(y_true, y_pred))\n",
    "    try:\n",
    "        rmse = float(mean_squared_error(y_true, y_pred, squared=False))\n",
    "    except TypeError:\n",
    "        rmse = float(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "    mae = float(mean_absolute_error(y_true, y_pred))\n",
    "    return {\"R2\": r2, \"RMSE\": rmse, \"MAE\": mae}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a292d8-7e40-4b46-a986-409518ae4d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:35:08.265702Z",
     "iopub.status.busy": "2026-01-11T09:35:08.265615Z",
     "iopub.status.idle": "2026-01-11T09:35:16.751969Z",
     "shell.execute_reply": "2026-01-11T09:35:16.750202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ridge (regularised linear) – modest grid\n",
    "ridge = Ridge(random_state=SEED)\n",
    "ridge_grid = {\"model__alpha\": np.logspace(-3, 3, 13)}\n",
    "\n",
    "pipe_ridge = Pipeline([(\"pre\", pre), (\"model\", ridge)])\n",
    "gs_ridge = GridSearchCV(\n",
    "    estimator=pipe_ridge,\n",
    "    param_grid=ridge_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",  # works if supported; fallback handled below\n",
    "    cv=3,\n",
    "    n_jobs=1,\n",
    "    refit=True\n",
    ")\n",
    "try:\n",
    "    gs_ridge.fit(X_train, y_train)\n",
    "except ValueError:\n",
    "    # Older sklearn may not have neg_root_mean_squared_error; fallback to neg_mean_squared_error\n",
    "    gs_ridge = GridSearchCV(\n",
    "        estimator=pipe_ridge,\n",
    "        param_grid=ridge_grid,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=3,\n",
    "        n_jobs=1,\n",
    "        refit=True\n",
    "    )\n",
    "    gs_ridge.fit(X_train, y_train)\n",
    "\n",
    "best_ridge = gs_ridge.best_estimator_\n",
    "pred_ridge = best_ridge.predict(X_test)\n",
    "m_ridge = {\"model\": \"Ridge\"} | evaluate(y_test, pred_ridge)\n",
    "m_ridge[\"alpha\"] = float(gs_ridge.best_params_[\"model__alpha\"])\n",
    "\n",
    "# Export coefficients (post-OHE feature names from TRAIN)\n",
    "ohe_train = best_ridge.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "feat_names = num_cols + list(ohe_train.get_feature_names_out(cat_cols))\n",
    "coefs = best_ridge.named_steps[\"model\"].coef_\n",
    "coef_df = pd.DataFrame({\"feature\": feat_names, \"coef\": coefs})\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
    "coef_df.sort_values(\"abs_coef\", ascending=False).to_csv(TAB_DIR/\"table_5_2_ridge_coefficients_loopB.csv\", index=False)\n",
    "\n",
    "# Save artifact\n",
    "joblib.dump(best_ridge, ART_DIR/\"pipe_ridge_loopB.joblib\")\n",
    "\n",
    "m_ridge, coef_df.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581a3cf-4579-4f5b-aa07-e9cc0125d4db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:35:16.754223Z",
     "iopub.status.busy": "2026-01-11T09:35:16.754108Z",
     "iopub.status.idle": "2026-01-11T09:36:59.956952Z",
     "shell.execute_reply": "2026-01-11T09:36:59.956417Z"
    }
   },
   "outputs": [],
   "source": [
    "if HGBR_AVAILABLE:\n",
    "    gbr = HistGradientBoostingRegressor(\n",
    "        random_state=SEED,\n",
    "        max_depth=None,\n",
    "        max_leaf_nodes=31,\n",
    "        learning_rate=0.1,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    param_grid = {\n",
    "        \"model__max_leaf_nodes\": [31, 63],\n",
    "        \"model__learning_rate\": [0.05, 0.1],\n",
    "        \"model__min_samples_leaf\": [10, 20, 40],\n",
    "    }\n",
    "else:\n",
    "    # Fallback to classic GradientBoostingRegressor\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        random_state=SEED,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=300,\n",
    "        max_depth=3\n",
    "    )\n",
    "    param_grid = {\n",
    "        \"model__learning_rate\": [0.05, 0.1],\n",
    "        \"model__n_estimators\": [200, 300, 500],\n",
    "        \"model__max_depth\": [2, 3],\n",
    "    }\n",
    "\n",
    "pipe_gbr = Pipeline([(\"pre\", pre), (\"model\", gbr)])\n",
    "gs_gbr = GridSearchCV(\n",
    "    estimator=pipe_gbr,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",  # use MSE for broad compatibility\n",
    "    cv=3,\n",
    "    n_jobs=1,\n",
    "    refit=True\n",
    ")\n",
    "gs_gbr.fit(X_train, y_train)\n",
    "\n",
    "best_gbr = gs_gbr.best_estimator_\n",
    "pipe_hgb = best_gbr\n",
    "pred_gbr = best_gbr.predict(X_test)\n",
    "m_gbr = {\"model\": \"HistGBR\" if HGBR_AVAILABLE else \"GBR\"} | evaluate(y_test, pred_gbr)\n",
    "m_gbr[\"best_params\"] = str(gs_gbr.best_params_)\n",
    "\n",
    "# Save artifact\n",
    "joblib.dump(best_gbr, ART_DIR/\"pipe_hgbr_loopB.joblib\")\n",
    "\n",
    "m_gbr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2effbef-ba30-4c8f-9f84-c95298c60c57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:36:59.971630Z",
     "iopub.status.busy": "2026-01-11T09:36:59.971409Z",
     "iopub.status.idle": "2026-01-11T09:36:59.985414Z",
     "shell.execute_reply": "2026-01-11T09:36:59.985044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop B results table\n",
    "loopB_results = pd.DataFrame([m_ridge, m_gbr]).sort_values(\"RMSE\")\n",
    "loopB_results.to_csv(TAB_DIR/\"model_loopB_results.csv\", index=False)\n",
    "\n",
    "# Combine with Loop A (if file exists)\n",
    "try:\n",
    "    loopA = pd.read_csv(TAB_DIR/\"model_baselines_loopA.csv\")\n",
    "    cmp_all = pd.concat([loopA.assign(loop=\"A\"), loopB_results.assign(loop=\"B\")], ignore_index=True)\n",
    "    cmp_all.sort_values([\"RMSE\",\"loop\"]).to_csv(TAB_DIR/\"model_comparison_all.csv\", index=False)\n",
    "    cmp_all\n",
    "except FileNotFoundError:\n",
    "    print(\"Loop A metrics not found; only Loop B results are saved.\")\n",
    "    loopB_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c252119-2fb8-43ff-b7a5-c9a15ea07668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:36:59.987656Z",
     "iopub.status.busy": "2026-01-11T09:36:59.987509Z",
     "iopub.status.idle": "2026-01-11T09:37:00.691922Z",
     "shell.execute_reply": "2026-01-11T09:37:00.691601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick the best model within Loop B\n",
    "bestB = m_ridge if m_ridge[\"RMSE\"] <= m_gbr[\"RMSE\"] else m_gbr\n",
    "best_name = bestB[\"model\"]\n",
    "best_pipe = best_ridge if best_name == \"Ridge\" else best_gbr\n",
    "best_pred = pred_ridge if best_name == \"Ridge\" else pred_gbr\n",
    "\n",
    "# Residuals vs Fitted\n",
    "resid = y_test - best_pred\n",
    "plt.figure()\n",
    "plt.scatter(best_pred, resid, s=12, alpha=0.7)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.title(f\"Residuals vs Fitted (Test) – {best_name} (Loop B)\")\n",
    "plt.xlabel(\"Fitted\"); plt.ylabel(\"Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR/\"figure_7_1_residuals_vs_fitted_loopB.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Actual vs Predicted\n",
    "plt.figure()\n",
    "plt.scatter(y_test, best_pred, s=12, alpha=0.7)\n",
    "plt.title(f\"Actual vs Predicted (Test) – {best_name} (Loop B)\")\n",
    "plt.xlabel(\"Actual (log_total_amount)\"); plt.ylabel(\"Predicted\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR/\"figure_7_1_actual_vs_pred_loopB.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Save per-row predictions (evidence)\n",
    "pred_df = pd.DataFrame({\n",
    "    \"index\": X_test.index,\n",
    "    \"book_ref\": df.loc[X_test.index, \"book_ref\"].values,\n",
    "    \"y_true\": y_test.values,\n",
    "    f\"y_pred_{best_name}_loopB\": best_pred\n",
    "})\n",
    "pred_df.to_csv(TAB_DIR/\"table_7_1_predictions_loopB.csv\", index=False)\n",
    "\n",
    "best_name, loopB_results.sort_values(\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary (Loop B):**\n",
    "- Trained stronger models (Ridge + HistGBR/GBR) on the SAME split as Loop A.\n",
    "- Exported metrics & predictions; produced residual plots; dumped fitted pipelines.\n",
    "- Wrote `model_comparison_all.csv` for Step 8.5 (iteration) comparison.\n",
    "\n",
    "**Next:** open `06_interpretation_compare.ipynb` for Step 8:\n",
    "- compare Loop A vs Loop B (tables/plots),\n",
    "- discuss business interpretation and next actions,\n",
    "- optionally add error-by-segment/cabin/route buckets for insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d72073-af9a-40a2-bd7f-6129350a223e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:37:00.697517Z",
     "iopub.status.busy": "2026-01-11T09:37:00.697415Z",
     "iopub.status.idle": "2026-01-11T09:37:01.248183Z",
     "shell.execute_reply": "2026-01-11T09:37:01.247766Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- 7.2 / Table XV: RUB errors for HistGBR (champion) ----\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def rmse_score(y_true, y_pred):\n",
    "    try:\n",
    "        return float(mean_squared_error(y_true, y_pred, squared=False))\n",
    "    except TypeError:\n",
    "        return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def backtransform_with_lognormal_correction(pipeline, X_tr, y_tr_log, X_te):\n",
    "    yhat_tr_log = pipeline.predict(X_tr)\n",
    "    sigma2 = np.mean((y_tr_log - yhat_tr_log)**2)\n",
    "    yhat_te_log = pipeline.predict(X_te)\n",
    "    return np.exp(yhat_te_log + 0.5 * sigma2)\n",
    "\n",
    "y_test_rub = np.exp(y_test_log)\n",
    "yhat_rub = backtransform_with_lognormal_correction(pipe_hgb, X_train, y_train_log, X_test)\n",
    "rub_row = pd.DataFrame([[\n",
    "    \"HistGradientBoosting (Loop B)\",\n",
    "    rmse_score(y_test_rub, yhat_rub),\n",
    "    mean_absolute_error(y_test_rub, yhat_rub),\n",
    "    float(np.median(np.abs(y_test_rub - yhat_rub)))\n",
    "]], columns=[\"Model\",\"RMSE_RUB\",\"MAE_RUB\",\"Median_AE_RUB\"])\n",
    "\n",
    "# Append/merge with Loop A RUB table\n",
    "path_a = TAB_DIR/\"table_7_2_RUB_errors_loopA.csv\"\n",
    "rub_all = pd.concat([pd.read_csv(path_a), rub_row], ignore_index=True) if path_a.exists() else rub_row\n",
    "rub_all.to_csv(TAB_DIR/\"table_7_2_RUB_errors_all.csv\", index=False)\n",
    "rub_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299be2f-df60-4676-98b1-553f9b1916dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:37:01.249919Z",
     "iopub.status.busy": "2026-01-11T09:37:01.249805Z",
     "iopub.status.idle": "2026-01-11T09:37:09.745620Z",
     "shell.execute_reply": "2026-01-11T09:37:09.744886Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- 8.2.1: Test-set permutation importance for HistGBR ----\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "pre = pipe_hgb.named_steps.get(\"pre\", pipe_hgb.named_steps.get(\"preprocessor\"))\n",
    "feat_names = getattr(pre, \"get_feature_names_out\", lambda: np.array([]))().tolist()\n",
    "r = permutation_importance(pipe_hgb, X_test, y_test_log, n_repeats=5, random_state=42, scoring=\"r2\")\n",
    "\n",
    "# Fallback to generic names if transformer cannot provide names\n",
    "if len(feat_names) != len(r.importances_mean):\n",
    "    feat_names = [f\"f{i}\" for i in range(len(r.importances_mean))]\n",
    "\n",
    "pi = (pd.DataFrame({\"feature\": feat_names, \"importance_mean\": r.importances_mean, \"importance_std\": r.importances_std})\n",
    "        .sort_values(\"importance_mean\", ascending=False))\n",
    "pi.to_csv(TAB_DIR/\"table_8_2_1_histgbr_permutation_importance.csv\", index=False)\n",
    "pi.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700ed91-bf01-4cae-ac7d-42d54f104dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T09:37:09.749420Z",
     "iopub.status.busy": "2026-01-11T09:37:09.749237Z",
     "iopub.status.idle": "2026-01-11T10:00:48.086968Z",
     "shell.execute_reply": "2026-01-11T10:00:48.085438Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- 8.2.2: PDP/ICE for Lead, Duration, Cabin Index; 2-D PDP for (Lead, Duration) ----\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "one_d = [(\"avg_booking_lead_days\",), (\"avg_sched_duration_min\",), (\"max_cabin_index\",)]\n",
    "for f in one_d:\n",
    "    PartialDependenceDisplay.from_estimator(pipe_hgb, X_test, [f], kind=\"both\")\n",
    "    plt.title(f\"PDP/ICE — {f[0]} (HistGBR, test-set)\")\n",
    "    plt.show()\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(pipe_hgb, X_test,\n",
    "    [(\"avg_booking_lead_days\", \"avg_sched_duration_min\")])\n",
    "plt.title(\"2D PDP — (Lead, Duration) (HistGBR, test-set)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
